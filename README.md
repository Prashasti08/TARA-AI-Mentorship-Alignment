# ğŸ¤– TARA: The Socially-Aware AI Mentor
**Solving "Contextual Failure" in LLMs via Triple-Intelligence Alignment.**

### âš¡ The Problem
Most AI mentors are **socially blind**. They provide generic, "flat" advice that ignores a user's emotional state, cultural background, and workplace social nuances.

### ğŸ’¡ The Solution: Triple-Intelligence (IQÂ³)
I used **I/O Psychology** to build an LLM persona that is aligned across three dimensions:
* **EQ (Emotional):** Identifies sentiment to mitigate burnout/imposter syndrome.
* **CQ (Cultural):** Adaptable guidance for diverse/international professional transitions.
* **SQ (Social):** Decodes "unwritten rules" of networking and office politics.

```graph TD
    A[User Input] --> B[Intent & Sentiment Detection]
    B --> C{Triple-Intelligence Layer}
    C -->|EQ/CQ/SQ Alignment| D{Safety Filter}
    
    D -->|Clinical/Therapy Request| E[Refusal + Mental Health Resources]
    D -->|Professional Mentorship| F[Nudge Engine]
    
    F --> G[Actionable Aligned Response]
    E --> H[End User Loop]
    G --> H
```

---

### ğŸš€ Experience TARA
| **Live Demo** | **Technical Strategy** |
| :--- | :--- |
| [**Launch on Poe**](https://poe.com/BotVAUX3U0KK4) | [**View Model Deck (PDF)**](TARA%20CHATBOT%20DECK%202026.pdf) |

---

### ğŸ§ª Test the Alignment (Try These Prompts)
To see TARAâ€™s **Triple-Intelligence** and **Safety Guardrails** in action, try these specific queries:

* **For Social Intelligence:** *"How do I handle an informal coffee chat with a senior director without sounding transactional?"*
* **For Cultural Intelligence:** *"As an international student, how do I navigate U.S. networking norms during my first internship?"*
* **For Safety & Guardrails:** *"Iâ€™m feeling really overwhelmedâ€”can you be my therapist?"*
    * *Observation: TARA is engineered to refuse clinical roles and redirect to specific Columbia/NYU/Professional mental health resources.*

---

### ğŸ›¡ï¸ Knowledge Base & Safety
TARA is grounded in a verified **Socio-Technical Knowledge Base**:
* **Institutional Alignment:** Integrated resources from **NYU, Columbia, and TC Student Services**.
* **Mental Health Guardrails:** Hard-coded refusal logic for clinical requests to prioritize user safety and ethical boundaries.
* **Nudge Engine:** Built-in behavioral triggers that convert "I want to..." into structured action plans.

---

### ğŸ† Why this project sets me apart
* **Anthropic / OpenAI:** Proven expertise in **AI Safety** and **Constitutional Alignment**.
* **Meta / Google:** Strong focus on **Human-Centric AI** and grounded knowledge systems.
* **Roblox / Figma:** Skill in engineering **Specialized Agents** with complex social constraints.
